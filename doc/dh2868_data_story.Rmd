---
title: "Beatles data_story"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

The Bealtes have been a household name for decades. 
They are regarded by many as one of the great rock bands of all time, but what was it that made them so popular? 
Perhaps some exploratory data analysis might provide an answer.


Let's load our necessary, packages first.
```{r}
library(tidyverse)
library(tm)
library(wordcloud)
library(tidytext)
library(ggplot2)
library(syuzhet)
library(plotly)
library(data.table)
```
Then we shall load our processed lyrics. 
```{r}
load("../output/processed_lyrics.RData")

artists <- read.csv("../data/artists.csv")
```


For this analysis, I'm focusing on the beatles within the larger subgroup of rock artists.  
I'm splitting the data into beatles and non-beatles (formed around the same time) for comparison and contrast.

```{r}

artists_60_70s<- artists %>% 
  filter(Formed %in% c(1960:1970)) %>% 
  select(Artist)

beatles_lyrics <- dt_lyrics %>% 
  filter(artist =="beatles" & genre == "Rock")

other_lyrics <- dt_lyrics %>% 
  filter(artist %in% artists_60_70s$Artist & genre == "Rock" & artist != "beatles") 
```

When comparing the number of stemmed words per song for each group, it seems that the Beatles have a lower average count (51) than similar rock bands (63). But what if the other bands' distribution is skewed by outliers?

```{r}
# the number of stemmed words in each song by group
beatles.words_per_song <- sort(sapply(strsplit(beatles_lyrics$stemmedwords, " "), length))
other.words_per_song <- sort(sapply(strsplit(other_lyrics$stemmedwords, " "), length))


# mean, median, and spread
summary(beatles.words_per_song)
summary(other.words_per_song)

# resulting plot
boxplot(beatles.words_per_song, other.words_per_song, horizontal = T, names = c("beatles", "other"), col = "blue")
```

Even if we remove the higher outliers, the Beatles still have a lower average number of stemmed words.

```{r}


# finding outliers for each group
outliers1 <- boxplot(beatles.words_per_song)$out
outliers2 <- boxplot(other.words_per_song)$out

# remove outliers 

beatles.words_per_song2 <- beatles.words_per_song[-which(beatles.words_per_song %in% outliers1)]
other.words_per_song2 <-  other.words_per_song[-which(other.words_per_song %in% outliers2)]
# mean, median, and spread
summary(beatles.words_per_song2)
summary(other.words_per_song2)

# resulting plot
boxplot(beatles.words_per_song2, other.words_per_song2, horizontal = T, names = c("Beatles", "Other"), xlab = "Number of words per song", col = "blue")
```


Next, I'll convert the given stemmed words into a corpus and then a term document matrix, since the data was already processed and cleaned.

```{r}
# Created a function to streamline conversion to term document matrix

stem_to_corpus <- function(x){
  source <- VectorSource(x)
  corpus <- VCorpus(source)
  return (corpus)
}

# respective corpi
beatles.corpus <- stem_to_corpus(beatles_lyrics$stemmedwords)
other.corpus <- stem_to_corpus(other_lyrics$stemmedwords)
# respective tdm
beatles.tdm <- TermDocumentMatrix(beatles.corpus)
other.tdm <- TermDocumentMatrix(other.corpus)

#beatles.tdm <- removeSparseTerms(beatles.tdm, 0.99) # remove lower frequency terms
#other.tdm <- removeSparseTerms(other.tdm, 0.99) # remove lower frequency terms

# Conveting TDMs into dataframes of most frequent terms

# beatles
m.beatles <- as.matrix(beatles.tdm)
f.b <- sort(rowSums(m.beatles), decreasing=T)
beatles.word_freq<- data.frame(word= names(f.b), freq=f.b)

# other
m.other <- as.matrix(other.tdm)
f.other <- sort(rowSums(m.other), decreasing=T)
other.word_freq<- data.frame(word= names(f.other), freq=f.other)
```


Here are the respective word clouds.

```{r}
# wordcloud for beatles
set.seed(1)
wordcloud(words = beatles.word_freq$word, freq =beatles.word_freq$freq, max.words = 100, random.order=FALSE,
          colors=brewer.pal(8, "Dark2"))

# wordcloud for other
set.seed(1)
wordcloud(words = other.word_freq$word, freq =other.word_freq$freq, max.words = 100, random.order=FALSE,  
          colors=brewer.pal(8, "Dark2"))

```

Without evern looking at any quantitative summaries, it's clear that "love" is the most dominant word in both Beatles and Other rock groups.



```{r}
# top 20 terms
head(beatles.word_freq, 20)
head(other.word_freq, 20)
```


Based on the top twenty words in the respective dataframes, it seems that there is little difference between the most used words from Beatles lyrics and those of other rock groups of the sixties/seventies. 

The words for the most part seem synonymous with similar frequencies; though there is an exception for "cry" (possibly invoking a negative sentiment) which is the 10th most used word in the Beatles lyrics and 20th in other bands.


The relative frequency in the bar plots, table, boxplots and piecharts indicate there is some difference in the distributions of the Beatles words.

```{r}

# summation of all frequencies for each group
n1<-sum(beatles.word_freq$freq)
n2<-sum(other.word_freq$freq) 

# relative frequencies  for each group
beatles.rf20 <- round(head(beatles.word_freq$freq, 20)/n1, 3)
other.rf20 <- round(head(other.word_freq$freq, 20)/n2, 3)

# relative frequency table
data.table(cbind("Beatle words" = as.character(head(beatles.word_freq$word, 20)), 
                 "freq" = head(beatles.word_freq$freq, 20),
                 "r-freq" = head(beatles.word_freq$freq, 20)/n1))
data.table(cbind("Other words" = as.character(head(other.word_freq$word, 20)),
                 "freq" = head(other.word_freq$freq, 20),
                 "r-freq" = head(other.word_freq$freq, 20)/n2))
 
# barplots with 
barplot(beatles.rf20, las = 1,names.arg = head(beatles.word_freq$word, 20), col = rainbow(20), horiz = T )
barplot(other.rf20, las = 2,names.arg = head(other.word_freq$word, 20), col = rainbow(20),horiz = T )

```

```{r}

# save top 50 words as character strings

a<- as.character(head(beatles.word_freq$word, 50))  
b <- as.character(head(other.word_freq$word, 50)) 

# intersection of common popular words for beatles and other
v<- a[a %in% b]

# return in each group the word 
o<-other.word_freq %>% 
  filter(word %in% v) 

b<-beatles.word_freq %>% 
  filter( word %in% v) 

# merge frequencies by words
top33 <- merge(b, o, by="word")

barplot(top33$freq.x)
barplot(top33$freq.y)

```



```{r}


# piecharts 

#please note that the proportions in these pie charts are based on the number of frequencies in the top 20 words, not the whole data set

plot_ly(head(beatles.word_freq, 20 ), labels= ~word, values = ~freq, type = "pie") %>% 
  layout(title = 'Beatles Top 20 Words in Lyrics',
         xaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE),
         yaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE))
  
plot_ly(head(other.word_freq,20) , labels= ~word, values = ~freq, type = "pie") %>% 
  layout(title = 'Other Rock Bands Top 20 Words in Lyrics',
         xaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE),
         yaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE))
```



Sentiment analysis using "afinn" lexicon

```{r}
beatles.word_freq %>% 
  inner_join(get_sentiments("afinn")) %>%
  group_by(word) %>% 
  ggplot(aes(x = value, y = freq)) + 
  geom_bar(stat = "identity", alpha = 0.8)

  
```



```{r}
beatles.sentiments <- get_nrc_sentiment(beatles_lyrics$stemmedwords)
```


